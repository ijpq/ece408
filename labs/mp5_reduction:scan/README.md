# List Reduction

## Objective

Implement a kernel and associated host code that performs reduction of a 1D list stored in a C array. The reduction should give the sum of the list. You should implement the improved kernel discussed in the lecture. Your kernel should be able to handle input lists of arbitrary length.

## Prerequisites

Before starting this lab, make sure that:
- You have completed week 4 lecture videos

## Instruction
For simplicity, you can assume that the input list will contain at most 2048 x 65535 elements so that it can be handled by only one kernel launch. The boundary condition can be handled by filling ‘identity value (0 for sum)’ into the shared memory of the last block when the length is not a multiple of the thread block size. Write a host (CPU) loop to calculate the total of the reduction sums of each section generated by individual blocks.

Edit the code in the ‘Code’ tab to perform the following:
- allocate device memory
- copy host memory to device
- initialize thread block and kernel grid dimensions
- invoke CUDA kernel
- copy results from device to host
- deallocate device memory
- implement the improved reduction kernel
- use shared memory to reduce the number of global accesses, handle the boundary conditions when loading input list elements into the shared memory
- implement a CPU loop to perform final reduction based on the sums of sections generated by the thread blocks after copying the partial sum array back to the host memory

Instructions about where to place each part of the code is demarcated by the //@@ comment lines.

# Parallel Scan

## Objective

The purpose of this lab is to implement one or more kernels and their associated host code to perform parallel scan on a 1D list. The scan operator used will be addition. You should implement the work- efficient kernel discussed in lecture. Your kernel should be able to handle input lists of arbitrary length. However, for simplicity, you can assume that the input list will be at most 2,048 * 2,048 elements.

## Prerequisites

Before starting this lab, make sure that:
- You have completed all week 4 lecture videos
- You have completed all week 5 lecture videos
- You have completed the List Reduction Lab

## Instruction

The boundary condition can be handled by filling ‘identity value (0 for sum)’ into the shared memory of the last block when the length is not a multiple of the thread block size.

You will need to launch multiple kernels to complete the parallel scan as discussed in the lecture.

Edit the code in the code tab to perform the following:
- allocate device memory
- copy host memory to device
- initialize thread block and kernel grid dimensions
- invoke CUDA kernel
- copy results from device to host
- deallocate device memory
- implement the work-efficient scan kernel to generate per-block scan array and store the block sums into an auxiliary block sum array.
- use shared memory to reduce the number of global memory accesses, handle the boundary conditions when loading input list elements into the shared memory
- reuse the kernel to perform scan on the auxiliary block sum array to translate the elements into accumulative block sums. Note that this kernel will be launched with only one block.
- implement the kernel that adds the accumulative block sums to the appropriate elements of the per-block scan array to complete the scan for all the elements.

Instructions about where to place each part of the code is demarcated by the //@@ comment lines.
